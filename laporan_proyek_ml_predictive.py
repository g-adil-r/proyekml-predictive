# -*- coding: utf-8 -*-
"""Laporan proyek ML - Predictive.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ni6Ym5_cVCVXI0fSQUq9i_iP2M3ZSZLR

# **Laporan Proyek Machine Learning - Ghifari Adil Ruchiyat**

---
# **1. Import library**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pathlib
import seaborn as sns
# %matplotlib inline

from imblearn.over_sampling import SMOTE
from scipy.stats import pointbiserialr
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.preprocessing import StandardScaler

"""---
# **2. Data Understanding**

## 2.1 Data loading
"""

df1 = pd.read_csv('datatraining.txt')
df2 = pd.read_csv('datatest.txt')
df3 = pd.read_csv('datatest2.txt')
df = pd.concat([df1, df2, df3], ignore_index=True)
df

"""## 2.2 Cek missing value"""

df.isnull().sum()

"""## 2.3 Menampilkan informasi data"""

df.describe()

"""## 2.4 Visualisasi Data

### 2.4.1 Plot kelas
"""

fig, ax = plt.subplots()
df['Occupancy'].value_counts().plot(kind='bar')
ax.set_xticklabels(['Not Occupied', 'Occupied'], rotation=0)
plt.show()

"""### 2.4.2 Histogram feature numerik"""

dfNumeric = df.drop(columns=['Occupancy', 'date'])
dfNumeric.hist(bins=50, figsize=(12,9))
plt.show()

"""### 2.4.3 Grafik Histogram masing-masing kelas"""

for column in dfNumeric.columns:
    fig, ax = plt.subplots(figsize=(6,3))
    fig.suptitle(column)
    df.groupby("Occupancy")[column].hist(alpha=0.4, bins=50, legend=True)
    plt.legend(['Not Occupied', 'Occupied'])

"""### 2.4.4 Box Plot masing-masing kelas"""

for column in dfNumeric:
  fig, ax = plt.subplots(figsize=(6,4))
  fig.suptitle(column)
  ax.boxplot([df[column][df['Occupancy']==0], df[column][df['Occupancy']==1], df[column]])
  ax.set_xticklabels(['Not Occupied', 'Occupied', 'Overall'])

"""### 2.4.5 Correlation matrix

#### Menghitung Correlation Matrix dengan metode Cramer's V
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix", size=20)

"""---
# **3. Data Preparation**

## 3.1 Drop column Date, HumidityRatio, dan Humidity
"""

dfTrain = df1.drop(columns=['date', 'HumidityRatio', 'Humidity'])

"""## 3.2 Melakukan normalisasi"""

xTrain = dfTrain.drop(columns=('Occupancy'))
yTrain = dfTrain.Occupancy
xColumns = xTrain.columns

scaler = StandardScaler().fit(xTrain)
xTrain = scaler.transform(xTrain)

"""## 3.3 Oversampling dengan metode SMOTE"""

smote = SMOTE(random_state=1)
xTrain, yTrain = smote.fit_resample(xTrain, yTrain)

"""---
# **4. Modelling**

## 4.1 Membuat Model Baseline
"""

baselineModel = RandomForestClassifier(random_state=1)

"""## 4.2 Melatih Model Baseline"""

baselineModel.fit(xTrain, yTrain)

"""## 4.3 Menginisiasi Random Search"""

paramRanges = {
    'n_estimators': range(25, 501),
    'max_depth': [None] + list(range(3,21)),
    'max_features': ['sqrt', 'log2', None],
    'min_samples_split': range(2,6)
}

search = RandomizedSearchCV(RandomForestClassifier(random_state=1), paramRanges, random_state=1, n_iter=50)

"""## 4.4 Melakukan Random Search"""

search.fit(xTrain, yTrain)
tunedModel = search.best_estimator_
search.best_params_

"""## 4.5 Feature Importance"""

featureNames = [i for i in xColumns]
baselineImportances = pd.Series(baselineModel.feature_importances_, index=featureNames)
tunedImportances = pd.Series(tunedModel.feature_importances_, index=featureNames)
importances = pd.DataFrame({"Baseline":baselineImportances, "Tuned":tunedImportances})

fig, ax = plt.subplots(figsize=(6,4))
fig.suptitle("Feature Importance", fontsize=15)

importances.plot.bar(rot=0, ax=ax)
ax.set_ylabel("Mean decrease in impurity")

fig.tight_layout()

"""---
# **5. Evaluasi Model**

## 5.1 Menyiapkan dataset test
"""

dfTest = pd.concat([df2, df3])
xTest = dfTest.drop(columns=['Occupancy', 'date', 'HumidityRatio', 'Humidity'])
xTest = scaler.transform(xTest)
yTest = dfTest.Occupancy

"""## 5.2 Menyiapkan Dataframe untuk evaluasi"""

dfEval = pd.DataFrame()

models = {'Baseline': baselineModel, 'Tuned': tunedModel}

"""## 5.3 Menghitung metrik pada masing-masing model"""

for name, model in models.items():
    dfEval.loc['Accuracy', name] = accuracy_score(yTest, model.predict(xTest))
    dfEval.loc['F1 Score', name] = f1_score(yTest, model.predict(xTest))
    dfEval.loc['ROC-AUC', name] = roc_auc_score(yTest, model.predict(xTest))

dfEval

"""## 5.4 Plot evaluasi model"""

dfEval.plot(kind='bar', figsize=(6,4), rot=0) \
  .legend(loc='center left',bbox_to_anchor=(1.0, 0.5))

plt.show()

"""## 5.5 Confusion Matrix pada dataset test"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7,3))

sns.heatmap(data=confusion_matrix(yTest, baselineModel.predict(xTest)), ax=ax1, annot=True, fmt='d')
ax1.set_title('Model Baseline')
ax1.set_xlabel('Predicted')
ax1.set_ylabel('Actual')

sns.heatmap(data=confusion_matrix(yTest, tunedModel.predict(xTest)), ax=ax2, annot=True, fmt='d')
ax2.set_title('Model Tuned')
ax2.set_xlabel('Predicted')
ax2.set_ylabel('Actual')

fig.tight_layout()
plt.show()